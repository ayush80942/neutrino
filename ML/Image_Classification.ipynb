{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":909724,"sourceType":"datasetVersion","datasetId":481068}],"dockerImageVersionId":30056,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import *\nfrom keras import backend as K\nimport tensorflow as tf\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:42:39.484864Z","iopub.execute_input":"2024-03-06T14:42:39.485133Z","iopub.status.idle":"2024-03-06T14:42:39.489089Z","shell.execute_reply.started":"2024-03-06T14:42:39.485108Z","shell.execute_reply":"2024-03-06T14:42:39.488289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_m(y_true, y_pred):\n\n    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), 0.5),K.floatx())\n    true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.clip(y_true, 0, 1))\n    recall_ratio = true_positives / (possible_positives + K.epsilon())\n    return recall_ratio\n\ndef precision_m(y_true, y_pred):\n\n    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), 0.5), K.floatx())\n    true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(y_pred)\n    precision_ratio = true_positives / (predicted_positives + K.epsilon())\n    return precision_ratio\n\ndef f1_m(y_true, y_pred):\n    \n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:11:03.787143Z","iopub.execute_input":"2024-03-06T12:11:03.787905Z","iopub.status.idle":"2024-03-06T12:11:03.799303Z","shell.execute_reply.started":"2024-03-06T12:11:03.787855Z","shell.execute_reply":"2024-03-06T12:11:03.798281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_width, img_height = 160, 160\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)\n    \nbatch_size = 128\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:42:53.521926Z","iopub.execute_input":"2024-03-06T14:42:53.522269Z","iopub.status.idle":"2024-03-06T14:42:53.526640Z","shell.execute_reply.started":"2024-03-06T14:42:53.522239Z","shell.execute_reply":"2024-03-06T14:42:53.525866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   validation_split=0.15)\n\ntraining_set = train_datagen.flow_from_directory('../input/apparel-images-dataset',\n                                                 target_size = (img_width, img_height),\n                                                 batch_size = batch_size,\n                                                 subset='training')\n\nval_set = train_datagen.flow_from_directory('../input/apparel-images-dataset',\n                                                 target_size = (img_width, img_height),\n                                                 batch_size = batch_size,\n                                                 subset='validation')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:42:56.436320Z","iopub.execute_input":"2024-03-06T14:42:56.436691Z","iopub.status.idle":"2024-03-06T14:43:00.585974Z","shell.execute_reply.started":"2024-03-06T14:42:56.436648Z","shell.execute_reply":"2024-03-06T14:43:00.585054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=6, ncols=4,figsize = (15,20))\n\nfor X_batch, y_batch in training_set:\n    i=0\n    for row in ax:\n        for col in row:\n            col.imshow(X_batch[i])\n            i+=1\n    break\nplt.show()    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-06T14:43:05.362822Z","iopub.execute_input":"2024-03-06T14:43:05.363188Z","iopub.status.idle":"2024-03-06T14:43:08.445230Z","shell.execute_reply.started":"2024-03-06T14:43:05.363154Z","shell.execute_reply":"2024-03-06T14:43:08.441637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",patience=5,\n    verbose=1, mode=\"auto\",\n    restore_best_weights=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:43:14.064550Z","iopub.execute_input":"2024-03-06T14:43:14.064903Z","iopub.status.idle":"2024-03-06T14:43:14.069223Z","shell.execute_reply.started":"2024-03-06T14:43:14.064875Z","shell.execute_reply":"2024-03-06T14:43:14.068216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet50V2","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential()\n\nmodel.add( \n    tf.keras.applications.ResNet50V2(\n        input_shape = input_shape,\n        include_top = True,\n        weights     = None,\n        pooling     = 'max'\n        )\n)\n\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(24,activation='softmax'))\n\nmodel.compile(\n    optimizer = 'adam', \n    loss = 'categorical_crossentropy',               \n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:43:21.846248Z","iopub.execute_input":"2024-03-06T14:43:21.846591Z","iopub.status.idle":"2024-03-06T14:43:25.724635Z","shell.execute_reply.started":"2024-03-06T14:43:21.846563Z","shell.execute_reply":"2024-03-06T14:43:25.723847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(training_set,\n                    validation_data = val_set,\n                    epochs=25,\n                    callbacks = [c],\n                    verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T14:43:28.584969Z","iopub.execute_input":"2024-03-06T14:43:28.585323Z","iopub.status.idle":"2024-03-06T15:04:42.959620Z","shell.execute_reply.started":"2024-03-06T14:43:28.585295Z","shell.execute_reply":"2024-03-06T15:04:42.958529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Max F1-score in validation dataset = {max(history.history['val_accuracy'])}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T15:05:21.524889Z","iopub.execute_input":"2024-03-06T15:05:21.525227Z","iopub.status.idle":"2024-03-06T15:05:21.530137Z","shell.execute_reply.started":"2024-03-06T15:05:21.525200Z","shell.execute_reply":"2024-03-06T15:05:21.529195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img-p = '/kaggle/input/apparel-images-dataset/black_shirt/010dd4d14ca70e8f8713437bf4849ebe21225f8e.jpg'\n# from keras.preprocessing.image import img_to_array, load_img\n# import numpy as np\n\n# # Load the image\n# img_path = '/kaggle/input/apparel-images-dataset/black_shirt/010dd4d14ca70e8f8713437bf4849ebe21225f8e.jpg'\n# img = load_img(img_path, target_size=(img_width, img_height))\n\n# # Convert the image to an array\n# img_array = img_to_array(img)\n\n# # Expand the dimensions to match the input shape expected by the model\n# img_array = np.expand_dims(img_array, axis=0)\n\n# # Preprocess the image using the same preprocessing function used in training\n# preprocessed_img = train_datagen.standardize(img_array)\n\n# # Make predictions using the model\n# predictions = model.predict(preprocessed_img)\n# print(predictions)\n# model.predict('/kaggle/input/apparel-images-dataset/black_shirt/010dd4d14ca70e8f8713437bf4849ebe21225f8e.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T15:06:53.824455Z","iopub.execute_input":"2024-03-06T15:06:53.824814Z","iopub.status.idle":"2024-03-06T15:06:53.880851Z","shell.execute_reply.started":"2024-03-06T15:06:53.824782Z","shell.execute_reply":"2024-03-06T15:06:53.879975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import image\nimport numpy as np\n\n# # Load the trained model\n# model_path = '/kaggle/working/nsut-model'  # Path to your trained model file\n# model = tf.keras.models.load_model(model_path)\n\n# Function to preprocess the user-uploaded photo\ndef preprocess_user_photo(img_path, target_size=(img_width, img_height)):\n    img = image.load_img(img_path, target_size=target_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array /= 255.0  # Rescale pixel values to [0, 1] like training data\n    return img_array\n\n# Path to the user-uploaded photol\n\n# Preprocess the user-uploaded photo\npreprocessed_user_photo = preprocess_user_photo('/kaggle/input/apparel-images-dataset/brown_pants/00bc7186fc623c91bfa12607fd7e595ddd320617.jpg')\n\n# Make predictions using the model\npredictions = model.predict(preprocessed_user_photo)\n\n# Get the predicted class label\npredicted_class_index = np.argmax(predictions)\ndict1=['dress','pants','shirt','shoes','shorts','dress','pants','shirt','shoes','shorts','pants','shoes','shorts','pants','shoes','shorts','dress','pants','shoes','dress','pants','shoes','shorts']\nprint(dict1[predicted_class_index])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T15:22:10.605881Z","iopub.execute_input":"2024-03-06T15:22:10.606245Z","iopub.status.idle":"2024-03-06T15:22:10.662749Z","shell.execute_reply.started":"2024-03-06T15:22:10.606215Z","shell.execute_reply":"2024-03-06T15:22:10.661952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"nsut-model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T13:03:34.447448Z","iopub.execute_input":"2024-03-06T13:03:34.447806Z","iopub.status.idle":"2024-03-06T13:04:07.139036Z","shell.execute_reply.started":"2024-03-06T13:03:34.447758Z","shell.execute_reply":"2024-03-06T13:04:07.137955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/nsut-model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T12:55:08.546582Z","iopub.execute_input":"2024-03-06T12:55:08.547021Z","iopub.status.idle":"2024-03-06T12:55:41.575721Z","shell.execute_reply.started":"2024-03-06T12:55:08.546985Z","shell.execute_reply":"2024-03-06T12:55:41.574866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of saving a TensorFlow model as an HDF5 file\nmodel.save('/kaggle/working/model-ai.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T15:22:25.627785Z","iopub.execute_input":"2024-03-06T15:22:25.628147Z","iopub.status.idle":"2024-03-06T15:22:26.469156Z","shell.execute_reply.started":"2024-03-06T15:22:25.628114Z","shell.execute_reply":"2024-03-06T15:22:26.468402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rahul = tf.keras.models.load_model('/kaggle/working/model-ai.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T15:22:56.932180Z","iopub.execute_input":"2024-03-06T15:22:56.932517Z","iopub.status.idle":"2024-03-06T15:22:59.187250Z","shell.execute_reply.started":"2024-03-06T15:22:56.932490Z","shell.execute_reply":"2024-03-06T15:22:59.186431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import image\nimport numpy as np\n\n# # Load the trained model\n# model_path = '/kaggle/working/nsut-model'  # Path to your trained model file\n# model = tf.keras.models.load_model(model_path)\n\n# Function to preprocess the user-uploaded photo\ndef preprocess_user_photo(img_path, target_size=(img_width, img_height)):\n    img = image.load_img(img_path, target_size=target_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array /= 255.0  # Rescale pixel values to [0, 1] like training data\n    return img_array\n\n# Path to the user-uploaded photo\n\n# Preprocess the user-uploaded photo\npreprocessed_user_photo = preprocess_user_photo('/kaggle/input/apparel-images-dataset/brown_pants/00bc7186fc623c91bfa12607fd7e595ddd320617.jpg')\n\n# Make predictions using the model\npredictions = rahul.predict(preprocessed_user_photo)\n\n# Get the predicted class label\npredicted_class_index = np.argmax(predictions)\ndict1=['dress','pants','shirt','shoes','shorts','dress','pants','shirt','shoes','shorts','pants','shoes','shorts','pants','shoes','shorts','dress','pants','shoes','dress','pants','shoes','shorts']\nprint(dict1[predicted_class_index])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T15:23:21.826321Z","iopub.execute_input":"2024-03-06T15:23:21.826776Z","iopub.status.idle":"2024-03-06T15:23:22.602414Z","shell.execute_reply.started":"2024-03-06T15:23:21.826623Z","shell.execute_reply":"2024-03-06T15:23:22.601542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking","metadata":{}},{"cell_type":"code","source":"def models(input_size = input_shape):\n\n    inputs = tf.keras.layers.Input(input_size)\n    \n    base_model1 =     tf.keras.applications.ResNet50V2(\n        include_top = False,\n        weights     = None,\n        pooling     = 'max'\n        )(inputs)\n\n    base_model2 =     tf.keras.applications.Xception(\n        include_top = False,\n        weights     = None,\n        pooling     = 'max'\n        )(inputs)\n    \n    model = tf.keras.layers.Concatenate()([base_model1,base_model2])\n    \n    model = tf.keras.layers.Dense(512, activation='relu')(model)\n    model = tf.keras.layers.Dense(64, activation='relu')(model)\n    model = tf.keras.layers.Dense(24, activation='softmax')(model)\n\n    M = tf.keras.Model(inputs=inputs, outputs=model)\n    M.compile(\n        optimizer = 'adam', \n        loss = 'categorical_crossentropy',               \n        metrics=['accuracy',f1_m]\n    )\n    \n    return M\n\nmodel = models()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(training_set,\n                    validation_data = val_set,\n                    epochs=epochs,\n                    callbacks = [c],\n                    verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Max F1-score in validation dataset = {max(history.history['val_f1_m'])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}